{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9fe5fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 710 files belonging to 2 classes.\n",
      "Using 568 files for training.\n",
      "Found 710 files belonging to 2 classes.\n",
      "Using 142 files for validation.\n",
      "Class Weights Calculated: {0: 0.8328445747800587, 1: 1.251101321585903}\n",
      "\n",
      "Simplified and stabilized data pipeline is ready.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# --- Configuration ---\n",
    "ROOT = Path(r\"C:\\Users\\ARYAN\\swastha\\CP-AnemiC\")\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# --- Load Datasets ---\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    ROOT,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=SEED,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    ROOT,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=SEED,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "# --- Calculate Class Weights ---\n",
    "train_labels = np.concatenate([y for x, y in train_ds], axis=0)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(f\"Class Weights Calculated: {class_weight_dict}\")\n",
    "\n",
    "# --- Data Augmentation Layer ---\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "])\n",
    "\n",
    "# --- Configure Datasets for Performance ---\n",
    "# We no longer apply our own rescaling or white balancing.\n",
    "# The model will do it internally.\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"\\nSimplified and stabilized data pipeline is ready.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b178fec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Stable Training ---\n",
      "Epoch 1/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 552ms/step - accuracy: 0.5211 - auc: 0.4770 - loss: 0.7389 - val_accuracy: 0.4648 - val_auc: 0.4930 - val_loss: 0.7279\n",
      "Epoch 2/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 291ms/step - accuracy: 0.4683 - auc: 0.4884 - loss: 0.7286 - val_accuracy: 0.5211 - val_auc: 0.5238 - val_loss: 0.6980\n",
      "Epoch 3/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 295ms/step - accuracy: 0.5211 - auc: 0.5329 - loss: 0.7082 - val_accuracy: 0.5282 - val_auc: 0.5703 - val_loss: 0.6824\n",
      "Epoch 4/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 341ms/step - accuracy: 0.5264 - auc: 0.5265 - loss: 0.7122 - val_accuracy: 0.5563 - val_auc: 0.6066 - val_loss: 0.6753\n",
      "Epoch 5/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 364ms/step - accuracy: 0.5704 - auc: 0.5896 - loss: 0.6850 - val_accuracy: 0.5704 - val_auc: 0.6441 - val_loss: 0.6662\n",
      "Epoch 6/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 294ms/step - accuracy: 0.5757 - auc: 0.5912 - loss: 0.6846 - val_accuracy: 0.5986 - val_auc: 0.6512 - val_loss: 0.6699\n",
      "Epoch 7/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 284ms/step - accuracy: 0.5634 - auc: 0.5793 - loss: 0.6917 - val_accuracy: 0.5986 - val_auc: 0.6753 - val_loss: 0.6613\n",
      "Epoch 8/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 282ms/step - accuracy: 0.5423 - auc: 0.5872 - loss: 0.6847 - val_accuracy: 0.6127 - val_auc: 0.6961 - val_loss: 0.6562\n",
      "Epoch 9/50\n",
      "\u001b[1m 5/18\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 233ms/step - accuracy: 0.5738 - auc: 0.6058 - loss: 0.6779"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# --- Train the Model ---\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Starting Stable Training ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 50\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Training Complete ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# --- Final Evaluation ---\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ARYAN\\swastha\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ARYAN\\swastha\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(begin_step)\n\u001b[1;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(end_step, logs)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\ARYAN\\swastha\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    219\u001b[0m     ):\n\u001b[1;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ARYAN\\swastha\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ARYAN\\swastha\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\ARYAN\\swastha\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ARYAN\\swastha\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ARYAN\\swastha\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\ARYAN\\swastha\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\ARYAN\\swastha\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ARYAN\\swastha\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\ARYAN\\swastha\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# --- Model Definition with Built-in Preprocessing ---\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# Define the input layer\n",
    "inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
    "\n",
    "# Apply data augmentation\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "# Use the official EfficientNetV2 preprocessing layer\n",
    "# This is much more stable than our custom function.\n",
    "x = tf.keras.applications.efficientnet_v2.preprocess_input(x)\n",
    "\n",
    "# Load the base model, ensuring it's not trainable initially\n",
    "base_model = tf.keras.applications.EfficientNetV2B0(\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "# Run the preprocessed data through the base model\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# Add our custom classification head\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# --- Compile the Model ---\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# --- Define a more patient EarlyStopping callback ---\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc',\n",
    "    patience=8, # More patience before stopping\n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# --- Train the Model ---\n",
    "print(\"--- Starting Stable Training ---\")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=50,\n",
    "    validation_data=val_ds,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "print(\"\\n--- Training Complete ---\")\n",
    "\n",
    "# --- Final Evaluation ---\n",
    "loss, accuracy, auc = model.evaluate(val_ds)\n",
    "print(f\"\\nFinal Validation Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Final Validation AUC: {auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d1c3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Advanced Training with LR Warm-up ---\n",
      "Epoch 1/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 561ms/step - accuracy: 0.6092 - auc: 0.6108 - loss: 0.6836 - val_accuracy: 0.6197 - val_auc: 0.7136 - val_loss: 0.6558\n",
      "Epoch 2/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 367ms/step - accuracy: 0.5493 - auc: 0.5799 - loss: 0.6877 - val_accuracy: 0.6620 - val_auc: 0.7138 - val_loss: 0.6381\n",
      "Epoch 3/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 376ms/step - accuracy: 0.5968 - auc: 0.6548 - loss: 0.6541 - val_accuracy: 0.6901 - val_auc: 0.7220 - val_loss: 0.6329\n",
      "Epoch 4/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 357ms/step - accuracy: 0.5739 - auc: 0.6111 - loss: 0.6747 - val_accuracy: 0.6831 - val_auc: 0.7359 - val_loss: 0.6247\n",
      "Epoch 5/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 360ms/step - accuracy: 0.6056 - auc: 0.6484 - loss: 0.6613 - val_accuracy: 0.6831 - val_auc: 0.7579 - val_loss: 0.6220\n",
      "Epoch 6/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 366ms/step - accuracy: 0.6004 - auc: 0.6563 - loss: 0.6553 - val_accuracy: 0.6901 - val_auc: 0.7609 - val_loss: 0.6240\n",
      "Epoch 7/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 291ms/step - accuracy: 0.5880 - auc: 0.6063 - loss: 0.6776 - val_accuracy: 0.6761 - val_auc: 0.7658 - val_loss: 0.6279\n",
      "Epoch 8/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 282ms/step - accuracy: 0.6268 - auc: 0.6335 - loss: 0.6718 - val_accuracy: 0.7113 - val_auc: 0.7634 - val_loss: 0.6330\n",
      "Epoch 9/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 285ms/step - accuracy: 0.6109 - auc: 0.6332 - loss: 0.6697 - val_accuracy: 0.6690 - val_auc: 0.7623 - val_loss: 0.6415\n",
      "Epoch 10/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 314ms/step - accuracy: 0.6285 - auc: 0.6463 - loss: 0.6621 - val_accuracy: 0.6901 - val_auc: 0.7704 - val_loss: 0.6293\n",
      "Epoch 11/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 380ms/step - accuracy: 0.6197 - auc: 0.6540 - loss: 0.6546 - val_accuracy: 0.6690 - val_auc: 0.7693 - val_loss: 0.6387\n",
      "Epoch 12/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 369ms/step - accuracy: 0.6144 - auc: 0.6668 - loss: 0.6498 - val_accuracy: 0.6408 - val_auc: 0.7638 - val_loss: 0.6356\n",
      "Epoch 13/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 383ms/step - accuracy: 0.6232 - auc: 0.6730 - loss: 0.6471 - val_accuracy: 0.6620 - val_auc: 0.7667 - val_loss: 0.6429\n",
      "Epoch 14/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 351ms/step - accuracy: 0.6268 - auc: 0.6757 - loss: 0.6458 - val_accuracy: 0.6690 - val_auc: 0.7776 - val_loss: 0.6271\n",
      "Epoch 15/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 350ms/step - accuracy: 0.6162 - auc: 0.6712 - loss: 0.6482 - val_accuracy: 0.6831 - val_auc: 0.7855 - val_loss: 0.6230\n",
      "Epoch 16/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 347ms/step - accuracy: 0.6092 - auc: 0.6541 - loss: 0.6562 - val_accuracy: 0.6972 - val_auc: 0.7909 - val_loss: 0.6224\n",
      "Epoch 17/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 360ms/step - accuracy: 0.6127 - auc: 0.6571 - loss: 0.6567 - val_accuracy: 0.7324 - val_auc: 0.7952 - val_loss: 0.6074\n",
      "Epoch 18/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 363ms/step - accuracy: 0.6373 - auc: 0.6760 - loss: 0.6416 - val_accuracy: 0.7254 - val_auc: 0.7954 - val_loss: 0.6107\n",
      "Epoch 19/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 351ms/step - accuracy: 0.6162 - auc: 0.6705 - loss: 0.6478 - val_accuracy: 0.7113 - val_auc: 0.7916 - val_loss: 0.6107\n",
      "Epoch 20/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 336ms/step - accuracy: 0.6232 - auc: 0.6747 - loss: 0.6430 - val_accuracy: 0.6831 - val_auc: 0.7890 - val_loss: 0.6122\n",
      "Epoch 21/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 344ms/step - accuracy: 0.6021 - auc: 0.6710 - loss: 0.6443 - val_accuracy: 0.6901 - val_auc: 0.7913 - val_loss: 0.6122\n",
      "Epoch 22/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 342ms/step - accuracy: 0.6532 - auc: 0.7006 - loss: 0.6329 - val_accuracy: 0.6901 - val_auc: 0.7950 - val_loss: 0.6135\n",
      "Epoch 23/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 338ms/step - accuracy: 0.6479 - auc: 0.6906 - loss: 0.6421 - val_accuracy: 0.7183 - val_auc: 0.7967 - val_loss: 0.6088\n",
      "Epoch 24/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 337ms/step - accuracy: 0.6338 - auc: 0.6981 - loss: 0.6328 - val_accuracy: 0.7324 - val_auc: 0.8012 - val_loss: 0.5971\n",
      "Epoch 25/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 333ms/step - accuracy: 0.6620 - auc: 0.7130 - loss: 0.6276 - val_accuracy: 0.7254 - val_auc: 0.8025 - val_loss: 0.5989\n",
      "Epoch 26/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 337ms/step - accuracy: 0.6444 - auc: 0.6893 - loss: 0.6382 - val_accuracy: 0.7254 - val_auc: 0.8055 - val_loss: 0.6008\n",
      "Epoch 27/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 374ms/step - accuracy: 0.6391 - auc: 0.6964 - loss: 0.6289 - val_accuracy: 0.7254 - val_auc: 0.8059 - val_loss: 0.5977\n",
      "Epoch 28/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 355ms/step - accuracy: 0.6004 - auc: 0.6652 - loss: 0.6485 - val_accuracy: 0.7465 - val_auc: 0.8073 - val_loss: 0.5940\n",
      "Epoch 29/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 344ms/step - accuracy: 0.6549 - auc: 0.7127 - loss: 0.6253 - val_accuracy: 0.7535 - val_auc: 0.8078 - val_loss: 0.6016\n",
      "Epoch 30/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 339ms/step - accuracy: 0.6285 - auc: 0.6853 - loss: 0.6381 - val_accuracy: 0.7465 - val_auc: 0.8116 - val_loss: 0.5987\n",
      "Epoch 31/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 317ms/step - accuracy: 0.6496 - auc: 0.7068 - loss: 0.6299 - val_accuracy: 0.7535 - val_auc: 0.8125 - val_loss: 0.6028\n",
      "Epoch 32/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 316ms/step - accuracy: 0.6620 - auc: 0.7248 - loss: 0.6194 - val_accuracy: 0.7535 - val_auc: 0.8133 - val_loss: 0.5992\n",
      "Epoch 33/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 323ms/step - accuracy: 0.6285 - auc: 0.7025 - loss: 0.6260 - val_accuracy: 0.7676 - val_auc: 0.8133 - val_loss: 0.5968\n",
      "Epoch 34/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 294ms/step - accuracy: 0.6356 - auc: 0.6781 - loss: 0.6444 - val_accuracy: 0.7535 - val_auc: 0.8135 - val_loss: 0.5981\n",
      "Epoch 35/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 260ms/step - accuracy: 0.6408 - auc: 0.6887 - loss: 0.6404 - val_accuracy: 0.7535 - val_auc: 0.8147 - val_loss: 0.6024\n",
      "Epoch 36/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 255ms/step - accuracy: 0.6408 - auc: 0.6845 - loss: 0.6379 - val_accuracy: 0.7465 - val_auc: 0.8154 - val_loss: 0.6037\n",
      "Epoch 37/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 254ms/step - accuracy: 0.6373 - auc: 0.7020 - loss: 0.6333 - val_accuracy: 0.7606 - val_auc: 0.8156 - val_loss: 0.6014\n",
      "Epoch 38/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 250ms/step - accuracy: 0.6514 - auc: 0.7230 - loss: 0.6175 - val_accuracy: 0.7535 - val_auc: 0.8151 - val_loss: 0.5975\n",
      "Epoch 39/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 251ms/step - accuracy: 0.6532 - auc: 0.7085 - loss: 0.6292 - val_accuracy: 0.7606 - val_auc: 0.8138 - val_loss: 0.5981\n",
      "Epoch 40/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 249ms/step - accuracy: 0.6338 - auc: 0.6800 - loss: 0.6403 - val_accuracy: 0.7676 - val_auc: 0.8138 - val_loss: 0.5995\n",
      "Epoch 41/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 251ms/step - accuracy: 0.6637 - auc: 0.7247 - loss: 0.6160 - val_accuracy: 0.7535 - val_auc: 0.8157 - val_loss: 0.6006\n",
      "Epoch 42/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 256ms/step - accuracy: 0.6180 - auc: 0.6791 - loss: 0.6395 - val_accuracy: 0.7535 - val_auc: 0.8139 - val_loss: 0.6016\n",
      "Epoch 43/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 254ms/step - accuracy: 0.6831 - auc: 0.7269 - loss: 0.6163 - val_accuracy: 0.7535 - val_auc: 0.8145 - val_loss: 0.6006\n",
      "Epoch 44/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 252ms/step - accuracy: 0.6479 - auc: 0.7128 - loss: 0.6263 - val_accuracy: 0.7535 - val_auc: 0.8157 - val_loss: 0.6002\n",
      "Epoch 45/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - accuracy: 0.6585 - auc: 0.7233 - loss: 0.6148 - val_accuracy: 0.7535 - val_auc: 0.8146 - val_loss: 0.6011\n",
      "Epoch 46/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 301ms/step - accuracy: 0.6567 - auc: 0.7420 - loss: 0.6070 - val_accuracy: 0.7535 - val_auc: 0.8149 - val_loss: 0.6010\n",
      "Epoch 47/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 292ms/step - accuracy: 0.6479 - auc: 0.7217 - loss: 0.6237 - val_accuracy: 0.7535 - val_auc: 0.8139 - val_loss: 0.6004\n",
      "Epoch 48/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 283ms/step - accuracy: 0.6549 - auc: 0.7099 - loss: 0.6274 - val_accuracy: 0.7535 - val_auc: 0.8144 - val_loss: 0.6004\n",
      "Epoch 49/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 281ms/step - accuracy: 0.6426 - auc: 0.6868 - loss: 0.6382 - val_accuracy: 0.7535 - val_auc: 0.8142 - val_loss: 0.6004\n",
      "Epoch 50/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 283ms/step - accuracy: 0.6514 - auc: 0.7138 - loss: 0.6238 - val_accuracy: 0.7535 - val_auc: 0.8142 - val_loss: 0.6004\n",
      "Epoch 51/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 282ms/step - accuracy: 0.6356 - auc: 0.6976 - loss: 0.6318 - val_accuracy: 0.7535 - val_auc: 0.8142 - val_loss: 0.6004\n",
      "Epoch 52/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - accuracy: 0.6444 - auc: 0.6985 - loss: 0.6299 - val_accuracy: 0.7535 - val_auc: 0.8142 - val_loss: 0.6004\n",
      "Epoch 53/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 294ms/step - accuracy: 0.6479 - auc: 0.7102 - loss: 0.6253 - val_accuracy: 0.7535 - val_auc: 0.8142 - val_loss: 0.6004\n",
      "Epoch 54/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 315ms/step - accuracy: 0.6479 - auc: 0.6937 - loss: 0.6319 - val_accuracy: 0.7535 - val_auc: 0.8142 - val_loss: 0.6004\n",
      "Epoch 55/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 318ms/step - accuracy: 0.6725 - auc: 0.7259 - loss: 0.6202 - val_accuracy: 0.7535 - val_auc: 0.8142 - val_loss: 0.6004\n",
      "Epoch 56/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 364ms/step - accuracy: 0.6901 - auc: 0.7356 - loss: 0.6126 - val_accuracy: 0.7535 - val_auc: 0.8142 - val_loss: 0.6004\n",
      "\n",
      "--- Evaluating with Test-Time Augmentation for Higher Accuracy ---\n",
      "\n",
      "Final Validation Accuracy (Standard): 75.35%\n",
      "Final Validation AUC (Standard): 0.8157\n",
      "------------------------------\n",
      "Final Validation AUC (with TTA): 0.8002\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Learning Rate Schedule with Warm-up ---\n",
    "# This is a more advanced learning rate schedule that can improve stability.\n",
    "initial_learning_rate = 0.001\n",
    "# The number of steps for the warm-up phase\n",
    "warmup_steps = int(0.1 * (len(train_ds) * 50)) # 10% of total steps for 50 epochs\n",
    "\n",
    "# Create a learning rate schedule with a cosine decay and warm-up\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=(len(train_ds) * 50) - warmup_steps, # Total steps minus warmup\n",
    "    alpha=0.0, # The minimum learning rate at the end of the decay\n",
    "    warmup_target=initial_learning_rate,\n",
    "    warmup_steps=warmup_steps\n",
    ")\n",
    "\n",
    "\n",
    "# --- 2. Re-compile the Model with the New Learning Rate Schedule ---\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "\n",
    "# --- 3. Define a More Patient EarlyStopping Callback ---\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc',\n",
    "    patience=15, # Even more patience to let the new LR schedule work\n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "# --- 4. Train the Model with the New Strategy ---\n",
    "print(\"--- Starting Advanced Training with LR Warm-up ---\")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=100, # Set a high limit; EarlyStopping will find the best\n",
    "    validation_data=val_ds,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "\n",
    "# --- 5. Evaluate with Test-Time Augmentation (TTA) ---\n",
    "print(\"\\n--- Evaluating with Test-Time Augmentation for Higher Accuracy ---\")\n",
    "tta_predictions = []\n",
    "tta_steps = 10\n",
    "\n",
    "# Create a new dataset from the validation set, unbatched\n",
    "unbatched_val_ds = val_ds.unbatch()\n",
    "\n",
    "for image, label in unbatched_val_ds:\n",
    "    # Get predictions for multiple augmented versions of the same image\n",
    "    augmented_images = tf.image.random_flip_left_right(tf.expand_dims(image, 0))\n",
    "    augmented_images = tf.image.random_flip_up_down(augmented_images)\n",
    "    # Add more augmentations here if needed...\n",
    "    \n",
    "    # Repeat the image and augment `tta_steps` times\n",
    "    predictions = model.predict(tf.repeat(augmented_images, tta_steps, axis=0), verbose=0)\n",
    "    \n",
    "    # Average the predictions\n",
    "    tta_predictions.append(np.mean(predictions))\n",
    "\n",
    "# Convert to a NumPy array for easier processing\n",
    "tta_predictions = np.array(tta_predictions)\n",
    "true_labels = np.concatenate([y for x, y in val_ds], axis=0)\n",
    "\n",
    "# Calculate final metrics with TTA\n",
    "tta_auc = tf.keras.metrics.AUC()\n",
    "tta_auc.update_state(true_labels, tta_predictions)\n",
    "\n",
    "print(f\"\\nFinal Validation Accuracy (Standard): {model.evaluate(val_ds, verbose=0)[1]*100:.2f}%\")\n",
    "print(f\"Final Validation AUC (Standard): {model.evaluate(val_ds, verbose=0)[2]:.4f}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Final Validation AUC (with TTA): {tta_auc.result().numpy():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e898bc",
   "metadata": {},
   "source": [
    "\n",
    "RESNET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9b57ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94668760/94668760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 0us/step\n",
      "--- Starting Training for the Second Base Model (ResNet50V2) ---\n",
      "Epoch 1/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 789ms/step - accuracy: 0.5158 - auc: 0.5020 - loss: 0.7930 - val_accuracy: 0.5352 - val_auc: 0.6692 - val_loss: 0.7376\n",
      "Epoch 2/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 754ms/step - accuracy: 0.5158 - auc: 0.5116 - loss: 0.7968 - val_accuracy: 0.5704 - val_auc: 0.6298 - val_loss: 0.6642\n",
      "Epoch 3/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 757ms/step - accuracy: 0.4965 - auc: 0.5046 - loss: 0.7701 - val_accuracy: 0.5704 - val_auc: 0.6199 - val_loss: 0.6538\n",
      "Epoch 4/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 749ms/step - accuracy: 0.5070 - auc: 0.5129 - loss: 0.7478 - val_accuracy: 0.5775 - val_auc: 0.6315 - val_loss: 0.6505\n",
      "Epoch 5/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 650ms/step - accuracy: 0.5352 - auc: 0.5367 - loss: 0.7529 - val_accuracy: 0.6479 - val_auc: 0.6431 - val_loss: 0.6540\n",
      "Epoch 6/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 594ms/step - accuracy: 0.5440 - auc: 0.5741 - loss: 0.7160 - val_accuracy: 0.5986 - val_auc: 0.6451 - val_loss: 0.6423\n",
      "Epoch 7/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 597ms/step - accuracy: 0.5194 - auc: 0.5369 - loss: 0.7281 - val_accuracy: 0.6479 - val_auc: 0.6643 - val_loss: 0.6393\n",
      "Epoch 8/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 590ms/step - accuracy: 0.5246 - auc: 0.5337 - loss: 0.7394 - val_accuracy: 0.6479 - val_auc: 0.6806 - val_loss: 0.6368\n",
      "Epoch 9/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 597ms/step - accuracy: 0.5423 - auc: 0.5540 - loss: 0.7334 - val_accuracy: 0.6549 - val_auc: 0.6868 - val_loss: 0.6309\n",
      "Epoch 10/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 587ms/step - accuracy: 0.5211 - auc: 0.5565 - loss: 0.7282 - val_accuracy: 0.6197 - val_auc: 0.6732 - val_loss: 0.6484\n",
      "Epoch 11/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 589ms/step - accuracy: 0.5405 - auc: 0.5720 - loss: 0.7166 - val_accuracy: 0.6268 - val_auc: 0.6903 - val_loss: 0.6366\n",
      "Epoch 12/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 590ms/step - accuracy: 0.5387 - auc: 0.5976 - loss: 0.6967 - val_accuracy: 0.6197 - val_auc: 0.7143 - val_loss: 0.6357\n",
      "Epoch 13/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 588ms/step - accuracy: 0.5599 - auc: 0.5885 - loss: 0.6967 - val_accuracy: 0.6761 - val_auc: 0.7425 - val_loss: 0.6186\n",
      "Epoch 14/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 587ms/step - accuracy: 0.5880 - auc: 0.6287 - loss: 0.6780 - val_accuracy: 0.7394 - val_auc: 0.7479 - val_loss: 0.6026\n",
      "Epoch 15/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 586ms/step - accuracy: 0.5933 - auc: 0.6140 - loss: 0.6846 - val_accuracy: 0.6831 - val_auc: 0.7316 - val_loss: 0.6116\n",
      "Epoch 16/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 589ms/step - accuracy: 0.5915 - auc: 0.5909 - loss: 0.7118 - val_accuracy: 0.6549 - val_auc: 0.7361 - val_loss: 0.6246\n",
      "Epoch 17/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 586ms/step - accuracy: 0.5423 - auc: 0.5901 - loss: 0.7039 - val_accuracy: 0.6690 - val_auc: 0.7236 - val_loss: 0.6157\n",
      "Epoch 18/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 597ms/step - accuracy: 0.5669 - auc: 0.6044 - loss: 0.6904 - val_accuracy: 0.6690 - val_auc: 0.7133 - val_loss: 0.6147\n",
      "Epoch 19/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 590ms/step - accuracy: 0.6021 - auc: 0.6365 - loss: 0.6707 - val_accuracy: 0.6479 - val_auc: 0.7099 - val_loss: 0.6208\n",
      "Epoch 20/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 589ms/step - accuracy: 0.6109 - auc: 0.6638 - loss: 0.6547 - val_accuracy: 0.6479 - val_auc: 0.7253 - val_loss: 0.6130\n",
      "Epoch 21/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 592ms/step - accuracy: 0.6127 - auc: 0.6566 - loss: 0.6578 - val_accuracy: 0.6620 - val_auc: 0.7377 - val_loss: 0.6258\n",
      "Epoch 22/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 589ms/step - accuracy: 0.6039 - auc: 0.6669 - loss: 0.6511 - val_accuracy: 0.6761 - val_auc: 0.7390 - val_loss: 0.6115\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# --- Define the ResNet50V2 model ---\n",
    "# We use the same data pipeline and image size (224x224)\n",
    "IMG_SHAPE_RESNET = (224, 224, 3)\n",
    "inputs_resnet = tf.keras.Input(shape=IMG_SHAPE_RESNET)\n",
    "\n",
    "# Apply the same augmentation\n",
    "x_resnet = data_augmentation(inputs_resnet)\n",
    "x_resnet = tf.keras.applications.resnet_v2.preprocess_input(x_resnet)\n",
    "\n",
    "base_model_resnet = tf.keras.applications.ResNet50V2(\n",
    "    include_top=False, weights='imagenet', input_shape=IMG_SHAPE_RESNET\n",
    ")\n",
    "base_model_resnet.trainable = False\n",
    "\n",
    "x_resnet = base_model_resnet(x_resnet, training=False)\n",
    "x_resnet = tf.keras.layers.GlobalAveragePooling2D()(x_resnet)\n",
    "x_resnet = tf.keras.layers.Dropout(0.3)(x_resnet)\n",
    "outputs_resnet = tf.keras.layers.Dense(1, activation='sigmoid')(x_resnet)\n",
    "\n",
    "model_resnet = tf.keras.Model(inputs_resnet, outputs_resnet)\n",
    "\n",
    "# --- Compile and Train the ResNet50V2 model ---\n",
    "model_resnet.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "print(\"--- Starting Training for the Second Base Model (ResNet50V2) ---\")\n",
    "history_resnet = model_resnet.fit(\n",
    "    train_ds,\n",
    "    epochs=50,\n",
    "    validation_data=val_ds,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=8, mode='max', restore_best_weights=True)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86484853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating predictions from base models...\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 265ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 485ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 383ms/step\n",
      "Training the meta-classifier...\n",
      "\n",
      "--- Stacking Ensemble Performance ---\n",
      "Final Ensemble Validation Accuracy: 76.06%\n",
      "Final Ensemble Validation AUC: 0.8315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# --- Generate Predictions from Both Base Models ---\n",
    "print(\"\\nGenerating predictions from base models...\")\n",
    "train_preds_effnet = model.predict(train_ds)\n",
    "val_preds_effnet = model.predict(val_ds)\n",
    "\n",
    "train_preds_resnet = model_resnet.predict(train_ds)\n",
    "val_preds_resnet = model_resnet.predict(val_ds)\n",
    "\n",
    "# --- Create the Meta-Dataset ---\n",
    "X_train_meta = np.hstack([train_preds_effnet, train_preds_resnet])\n",
    "X_val_meta = np.hstack([val_preds_effnet, val_preds_resnet])\n",
    "\n",
    "y_train_meta = np.concatenate([y for x, y in train_ds])\n",
    "y_val_meta = np.concatenate([y for x, y in val_ds])\n",
    "\n",
    "# --- Train the Meta-Classifier ---\n",
    "print(\"Training the meta-classifier...\")\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(X_train_meta, y_train_meta)\n",
    "\n",
    "# --- Evaluate the Final Ensemble Model ---\n",
    "final_predictions = meta_model.predict_proba(X_val_meta)[:, 1]\n",
    "ensemble_auc = roc_auc_score(y_val_meta, final_predictions)\n",
    "ensemble_accuracy = accuracy_score(y_val_meta, final_predictions > 0.5)\n",
    "\n",
    "print(\"\\n--- Stacking Ensemble Performance ---\")\n",
    "print(f\"Final Ensemble Validation Accuracy: {ensemble_accuracy*100:.2f}%\")\n",
    "print(f\"Final Ensemble Validation AUC: {ensemble_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a549974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All three models have been saved successfully:\n",
      "Files created: efficientnet_model.keras, resnet_model.keras, meta_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# --- Save the Keras base models in the recommended .keras format ---\n",
    "model.save('efficientnet_model.keras')\n",
    "model_resnet.save('resnet_model.keras')\n",
    "\n",
    "# --- Save the Scikit-learn meta-model ---\n",
    "joblib.dump(meta_model, 'meta_model.joblib')\n",
    "\n",
    "print(\"All three models have been saved successfully:\")\n",
    "print(\"Files created: efficientnet_model.keras, resnet_model.keras, meta_model.joblib\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
